{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! if [ ! $pip_done ]; then pip install -q transformers ;fi \n",
    "\n",
    "# # command-line\n",
    "# # pip uninstall folium\n",
    "# ! pip install folium==0.2.1\n",
    "\n",
    "# ! if [ ! $pip_done ]; then pip install -q datasets jiwer ;fi \n",
    "# ! if [ ! $pip_done ]; then pip install -q sentencepiece ;fi \n",
    "\n",
    "# pip_done = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing parameters: Only run on N samples if test=True\n",
    "max_sample_test = 1000\n",
    "# Maximum length of equation in # of tokens\n",
    "max_length_token = 100\n",
    "# Size of vocab in tokenizer, i.e. distinct number of tokens to learn\n",
    "vocab_size = 600\n",
    "# Batch size for DataLoader\n",
    "batch_size = 16\n",
    "# Version number for model\n",
    "version = 5\n",
    "# Report loss every N steps\n",
    "report_step = 100 \n",
    "# Number of epochs to train. Each epoch is one cycle of training over full training set.\n",
    "num_epoch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPython magic to enable inline display of matplotlib plots\n",
    "%matplotlib inline\n",
    "from IPython.display import Image as ipyImage\n",
    "from IPython.display import display, Latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(pth, type = None):\n",
    "    df = pd.read_csv(join(data_dir, pth), header=None, sep=' ')\n",
    "    df = df.drop(2, axis=1)\n",
    "    df.rename(columns={0: \"text_index\", 1: \"file_name\"}, inplace=True)\n",
    "\n",
    "    # Replace text with formulas\n",
    "    df['text'] = df.apply (lambda row: formulas[int(row['text_index'])], axis=1)\n",
    "    df['len'] = df.apply (lambda row: row['text'].count(' '), axis=1)\n",
    "    # Sort by ascending length of formula\n",
    "    df_sorted = df.sort_values(by=\"len\")\n",
    "    df_filtered = df_sorted[df_sorted['len'] > 0 ]\n",
    "    df_trunc = df_filtered[df_filtered['len'] <= max_length_token ]\n",
    "    df = df_trunc\n",
    "    df = df.reset_index(drop=True)\n",
    "    globals()[\"{}_df\".format(type)] = df\n",
    "    # print(type+'_dataframe',df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os.path import join\n",
    "\n",
    "data_dir = './data/'\n",
    "\n",
    "# formulas_file = join(data_dir, \"im2latex_formulas.lst\")\n",
    "# with open(formulas_file, 'r', encoding='ISO-8859-1') as f:\n",
    "#     formulas = [formula.strip('\\n') for formula in f.readlines()]\n",
    "\n",
    "formulas_file = join(data_dir, \"im2latex_formulas_utf.lst\")\n",
    "# linux 인코딩 변환 : iconv -c -f ISO-8859-1 -t utf-8 im2latex_formulas.lst > im2latex_formulas_utf.lst\n",
    "with open(formulas_file, 'r') as f:\n",
    "    formulas = [formula.strip('\\n') for formula in f.readlines()]\n",
    "\n",
    "# train_df/test_df/validate_df\n",
    "types = ['train', 'test', 'validate']\n",
    "for type in types:\n",
    "    pth = 'im2latex_{}.lst'.format(type)\n",
    "    preprocess_df(pth, type = type)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59930    L=-{1\\over g^2} \\!\\int\\! d^2 x \\Bigl( {1\\over ...\n",
      "Name: text, dtype: object\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=128x64>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "# Show some images as sanity check\n",
    "sample = train_df.sample(n=1)\n",
    "print(sample['text'])\n",
    "# ipyImage는 출력이 안되는 오류 자주 발생\n",
    "# ipyImage(join(data_dir, 'formula_images_processed', sample.iloc[0]['file_name']+\".png\"))\n",
    "image = Image.open(join(data_dir, 'formula_images_processed', sample.iloc[0]['file_name']+\".png\"))\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train word level tokenizer\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "max_length = max_length_token\n",
    "tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n",
    "tokenizer.enable_padding(length=max_length)\n",
    "tokenizer.enable_truncation(max_length=max_length)\n",
    "\n",
    "from tokenizers.trainers import WordLevelTrainer\n",
    "trainer = WordLevelTrainer(special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"],\n",
    "                     vocab_size=vocab_size,\n",
    "                     show_progress=True,\n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "\n",
    "from tokenizers.processors import TemplateProcessing\n",
    "tokenizer.post_processor = TemplateProcessing(\n",
    "    single=\"[CLS] $A [SEP]\",\n",
    "    pair=\"[CLS] $A [SEP] $B:1 [SEP]:1\",\n",
    "    special_tokens=[\n",
    "        (\"[CLS]\", 1),\n",
    "        (\"[SEP]\", 2),\n",
    "    ],\n",
    ")\n",
    "\n",
    "files = [formulas_file]\n",
    "tokenizer.train(files, trainer)\n",
    "\n",
    "tokenizer.save(\"tokenizer-wordlevel.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '{\\\\', 'cal', 'L', '}=\\\\', 'frac', '{', '1', '}{', '2', '}\\\\', 'partial_', '{\\\\', 'mu', '}\\\\', 'phi', '\\\\', 'partial', '^{\\\\', 'mu', '}\\\\', 'phi', '+\\\\', 'frac', '{', '1', '}{', '2', '}\\\\', 'partial_', '{\\\\', 'mu', '}\\\\', 'chi', '\\\\', 'partial', '^{\\\\', 'mu', '}\\\\', 'chi', '-', 'U', '(\\\\', 'phi', ',\\\\', 'chi', '),', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "[1, 9, 46, 93, 136, 14, 6, 10, 23, 8, 13, 102, 9, 27, 13, 54, 5, 48, 32, 27, 13, 54, 76, 14, 6, 10, 23, 8, 13, 102, 9, 27, 13, 172, 5, 48, 32, 27, 13, 172, 16, 179, 30, 54, 49, 172, 176, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Sanity check of tokenizer\n",
    "i = 5\n",
    "\n",
    "print( tokenizer.encode(train_df.loc[i, 'text']).tokens )\n",
    "\n",
    "print( tokenizer.encode(train_df.loc[i, 'text']).ids )\n",
    "\n",
    "print( tokenizer.token_to_id(\"[PAD]\") )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "class IAMDataset(Dataset):\n",
    "    def __init__(self, root_dir, df, processor, tokenizer, max_target_length=max_length):\n",
    "        self.root_dir = root_dir\n",
    "        self.df = df\n",
    "        self.processor = processor\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_target_length = max_target_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # get file name + text \n",
    "        file_name = self.df['file_name'][idx]\n",
    "        text = self.df['text'][idx]\n",
    "        # prepare image (i.e. resize + normalize)\n",
    "        image = Image.open(self.root_dir + file_name+'.png').convert(\"RGB\")\n",
    "        pixel_values = self.processor(image, return_tensors=\"pt\").pixel_values\n",
    "#        # add labels (input_ids) by encoding the text\n",
    "#        labels = self.processor.tokenizer(text, \n",
    "#                                          padding=\"max_length\", \n",
    "#                                          max_length=self.max_target_length).input_ids\n",
    "#        # important: make sure that PAD tokens are ignored by the loss function\n",
    "#        labels = [label if label != self.processor.tokenizer.pad_token_id else -100 for label in labels]\n",
    "        labels = self.tokenizer.encode(text).ids\n",
    "        labels = [label if label != self.tokenizer.token_to_id(\"[PAD]\") else -100 for label in labels]\n",
    "\n",
    "        encoding = {\"pixel_values\": pixel_values.squeeze(), \"labels\": torch.tensor(labels)}\n",
    "        return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrOCRProcessor\n",
    "root_dir = join(data_dir, 'formula_images_processed/',) \n",
    "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-small-printed\", Use_fast= False)\n",
    "train_dataset = IAMDataset(root_dir=root_dir,\n",
    "                           df=train_df,\n",
    "                           processor=processor,\n",
    "                           tokenizer=tokenizer)\n",
    "valid_dataset = IAMDataset(root_dir=root_dir,\n",
    "                           df=validate_df,\n",
    "                           processor=processor,\n",
    "                           tokenizer=tokenizer)\n",
    "eval_dataset = IAMDataset(root_dir=root_dir,\n",
    "                           df=test_df,\n",
    "                           processor=processor,\n",
    "                           tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 78024\n",
      "Number of training examples: 8638\n",
      "Number of validation examples: 9699\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training examples:\", len(train_dataset))\n",
    "print(\"Number of training examples:\", len(valid_dataset))\n",
    "print(\"Number of validation examples:\", len(eval_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixel_values torch.Size([3, 384, 384])\n",
      "labels torch.Size([100])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAABACAIAAABdtOgoAAADWElEQVR4nO2asUv7QBTH75ILQShq/wBxca+Di9ClQ1dx8I8QNxcnoTgpFBf9F9z9AxxEEP0HXJxE3IuGEmzu8p5D7K8mFkma6+9B7322JvQ43qfNvbtvJCIKhg7v9yUcU2dc9lqSogBjjBwjZqojImaD2JngopMTgIhKqeFw+PLyMhgMhBBSyqoOpJRKqSiKRqORzZkuKBMBiCil7PV6GxsbV1dXW1tbOzs7Hx8flR5HAPD8/Hx4eLi2tnZ+fi6E0FrPZeILQ1ZfYwwi3t3dCSGur68R8e3tTQjR7/cRMUkSLMfn5+fFxcXBwYEQ4vj4uNJ33UQgIgAYY0aj0fb29srKCiJqrQGg0+m02+0kSYwxAFBpXCklCyjD9yPI931jzOPj4/7+vjEmSRIpZbfbvb+/11r7vl/+/2SMiaIIuQsqx2QNkFJ6nheGoVIquzIcDj3Pq9rPKKWCILA5x4Um1wUBAABM7nnez4/MPMgJ4Ir/f3JtKAA0Gg0x3n953pR9MmOX7xKnaRoEQbvdvrm50VorpRAxSZIZnubGGDFeUdI05b/U33hCCCklAARBsLu7e3t7my3FiHh2dnZ0dLS0tKS1Lr8UZ2s4IsZx7Pt+GIZznP4CkHWj2VYgiqJut7u5ufn09NRqtTqdThzH2a+4ZFcbx/Hl5eXe3t7y8vL6+vrp6enDwwMipmlqvYNeDCZHPYgopUzTtNfrra6uvr+/n5yc+L6fXS+pEwBeX1/DMGw0GgAwGAyazWaz2aw0iFPkztp+l4kLN2+Kh504PkxGRKXUDNUvDMj+/qbyaTNjF+70iWEBxEwXUPO59K/HqjOIIxQFYO1Et36q7BRFATUTXbSRKjtF8Ti6TqKLNlJl5/i5La6T6NpKlV1DTL1aNdGdR6rsCMX3gmZOdG2lyq5RXITrJLq2UmWnsLwR41S5KpYFcMWrYlMAcqpcnSlvR4uZEl2LqbJTTFmERfVE126q7BY/e9I6ia6tVNk1cgc1NRNdtJEqu4blk7Lftebq/82UTDh3e6ZMuGaq7BR8VkwM9+nEsABiWAAxLIAYFkAMCyCGBRDDAohhAcSwAGJYADEsgBgWQAwLIIYFEMMCiGEBxLAAYlgAMSyAGBZADAsghgUQwwKIYQHEfAGexWLn5Pl7CwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=128x64>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding = train_dataset[0]\n",
    "for k,v in encoding.items():\n",
    "  print(k, v.shape)\n",
    "image = Image.open(train_dataset.root_dir + train_df['file_name'][0]+'.png').convert(\"RGB\")\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\ label { eq : }{\\ cal U } _ {\\ hat { U }\\ hat { V }}= 0 .\n"
     ]
    }
   ],
   "source": [
    "labels = encoding['labels']\n",
    "labels[labels == -100] = tokenizer.token_to_id(\"[PAD]\")\n",
    "label_str = tokenizer.decode(labels.tolist(), skip_special_tokens=True)\n",
    "print(label_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "from torch.utils.data import DataLoader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=batch_size)\n",
    "validate_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-small-stage1 and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VisionEncoderDecoderModel(\n",
       "  (encoder): DeiTModel(\n",
       "    (embeddings): DeiTEmbeddings(\n",
       "      (patch_embeddings): PatchEmbeddings(\n",
       "        (projection): Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16))\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): DeiTEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): DeiTLayer(\n",
       "          (attention): DeiTAttention(\n",
       "            (attention): DeiTSelfAttention(\n",
       "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): DeiTSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DeiTIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DeiTOutput(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): DeiTLayer(\n",
       "          (attention): DeiTAttention(\n",
       "            (attention): DeiTSelfAttention(\n",
       "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): DeiTSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DeiTIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DeiTOutput(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): DeiTLayer(\n",
       "          (attention): DeiTAttention(\n",
       "            (attention): DeiTSelfAttention(\n",
       "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): DeiTSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DeiTIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DeiTOutput(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): DeiTLayer(\n",
       "          (attention): DeiTAttention(\n",
       "            (attention): DeiTSelfAttention(\n",
       "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): DeiTSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DeiTIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DeiTOutput(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): DeiTLayer(\n",
       "          (attention): DeiTAttention(\n",
       "            (attention): DeiTSelfAttention(\n",
       "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): DeiTSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DeiTIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DeiTOutput(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): DeiTLayer(\n",
       "          (attention): DeiTAttention(\n",
       "            (attention): DeiTSelfAttention(\n",
       "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): DeiTSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DeiTIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DeiTOutput(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (6): DeiTLayer(\n",
       "          (attention): DeiTAttention(\n",
       "            (attention): DeiTSelfAttention(\n",
       "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): DeiTSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DeiTIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DeiTOutput(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (7): DeiTLayer(\n",
       "          (attention): DeiTAttention(\n",
       "            (attention): DeiTSelfAttention(\n",
       "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): DeiTSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DeiTIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DeiTOutput(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (8): DeiTLayer(\n",
       "          (attention): DeiTAttention(\n",
       "            (attention): DeiTSelfAttention(\n",
       "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): DeiTSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DeiTIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DeiTOutput(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (9): DeiTLayer(\n",
       "          (attention): DeiTAttention(\n",
       "            (attention): DeiTSelfAttention(\n",
       "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): DeiTSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DeiTIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DeiTOutput(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (10): DeiTLayer(\n",
       "          (attention): DeiTAttention(\n",
       "            (attention): DeiTSelfAttention(\n",
       "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): DeiTSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DeiTIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DeiTOutput(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (11): DeiTLayer(\n",
       "          (attention): DeiTAttention(\n",
       "            (attention): DeiTSelfAttention(\n",
       "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): DeiTSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DeiTIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DeiTOutput(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "    (pooler): DeiTPooler(\n",
       "      (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (decoder): TrOCRForCausalLM(\n",
       "    (model): TrOCRDecoderWrapper(\n",
       "      (decoder): TrOCRDecoder(\n",
       "        (embed_tokens): Embedding(64044, 256, padding_idx=1)\n",
       "        (embed_positions): TrOCRLearnedPositionalEmbedding(514, 256)\n",
       "        (layernorm_embedding): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (layers): ModuleList(\n",
       "          (0): TrOCRDecoderLayer(\n",
       "            (self_attn): TrOCRAttention(\n",
       "              (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): TrOCRAttention(\n",
       "              (k_proj): Linear(in_features=384, out_features=256, bias=True)\n",
       "              (v_proj): Linear(in_features=384, out_features=256, bias=True)\n",
       "              (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): TrOCRDecoderLayer(\n",
       "            (self_attn): TrOCRAttention(\n",
       "              (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): TrOCRAttention(\n",
       "              (k_proj): Linear(in_features=384, out_features=256, bias=True)\n",
       "              (v_proj): Linear(in_features=384, out_features=256, bias=True)\n",
       "              (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): TrOCRDecoderLayer(\n",
       "            (self_attn): TrOCRAttention(\n",
       "              (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): TrOCRAttention(\n",
       "              (k_proj): Linear(in_features=384, out_features=256, bias=True)\n",
       "              (v_proj): Linear(in_features=384, out_features=256, bias=True)\n",
       "              (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): TrOCRDecoderLayer(\n",
       "            (self_attn): TrOCRAttention(\n",
       "              (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): TrOCRAttention(\n",
       "              (k_proj): Linear(in_features=384, out_features=256, bias=True)\n",
       "              (v_proj): Linear(in_features=384, out_features=256, bias=True)\n",
       "              (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): TrOCRDecoderLayer(\n",
       "            (self_attn): TrOCRAttention(\n",
       "              (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): TrOCRAttention(\n",
       "              (k_proj): Linear(in_features=384, out_features=256, bias=True)\n",
       "              (v_proj): Linear(in_features=384, out_features=256, bias=True)\n",
       "              (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): TrOCRDecoderLayer(\n",
       "            (self_attn): TrOCRAttention(\n",
       "              (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): TrOCRAttention(\n",
       "              (k_proj): Linear(in_features=384, out_features=256, bias=True)\n",
       "              (v_proj): Linear(in_features=384, out_features=256, bias=True)\n",
       "              (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (output_projection): Linear(in_features=256, out_features=64044, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import VisionEncoderDecoderModel\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-small-stage1\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set special tokens used for creating the decoder_input_ids from the labels\n",
    "model.config.decoder_start_token_id = tokenizer.token_to_id(\"[CLS]\")\n",
    "model.config.pad_token_id = tokenizer.token_to_id(\"[PAD]\")\n",
    "# make sure vocab size is set correctly\n",
    "model.config.vocab_size = vocab_size\n",
    "\n",
    "# set beam search parameters\n",
    "model.config.eos_token_id = tokenizer.token_to_id(\"[SEP]\")\n",
    "model.config.max_length = max_length #64\n",
    "model.config.early_stopping = True\n",
    "model.config.no_repeat_ngram_size = 3\n",
    "model.config.length_penalty = 2.0\n",
    "model.config.num_beams = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.tokenizer = tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "cer_metric = load_metric(\"cer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "cer_metric = load_metric(\"cer\")\n",
    "\n",
    "def compute_cer(pred_ids, label_ids):\n",
    "    pred_str = tokenizer.decode_batch(pred_ids.tolist(), skip_special_tokens=True)\n",
    "    label_ids[label_ids == -100] = tokenizer.token_to_id(\"[PAD]\")\n",
    "    label_str = tokenizer.decode_batch(label_ids.tolist(), skip_special_tokens=True)\n",
    "    \n",
    "    # Filter out empty label strings\n",
    "#    for l in enumerate(label_str):\n",
    "#        if not l:\n",
    "#            label_str.pop(l)\n",
    "#            pred_str.pop(l)\n",
    "\n",
    "    cer = cer_metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return cer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeeyoon/miniforge3/envs/imlatex/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "752e758a8ad04e1d95507fb187a4a5c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 16.471101760864258\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 5\n",
    "report_step = 100 \n",
    " \n",
    "from transformers import AdamW\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "for epoch in range(num_epoch):  # loop over the dataset multiple times\n",
    "    # train\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for i, batch in enumerate(tqdm(train_dataloader)):\n",
    "        # get the inputs\n",
    "        for k,v in batch.items():\n",
    "            batch[k] = v.to(device)\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        if i % report_step == 0: print(f\"Loss: {loss.item()}\") \n",
    "\n",
    "    print(f\"Loss after epoch {epoch}:\", train_loss/len(train_dataloader))\n",
    "    model.save_pretrained(f\"version_{version}/epoch_{epoch}\")\n",
    "\n",
    "\n",
    "model.save_pretrained(f\"version_{version}/final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(eval_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "i = 0\n",
    "for batch in (test_dataloader):\n",
    "    for k,v in batch.items():\n",
    "        batch[k] = v.to(device)\n",
    "    outputs = model.generate(batch[\"pixel_values\"].to(device))\n",
    "    px = batch[\"pixel_values\"][i].cpu().numpy()\n",
    "    labels = batch[\"labels\"][i]\n",
    "    pred = outputs[i]\n",
    "    break\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(px.transpose([1,2,0]), aspect=1/5)\n",
    "label_true = tokenizer.decode(labels.tolist()).replace(\" \", \"\")\n",
    "label_pred = tokenizer.decode(pred.tolist()).replace(\" \", \"\")\n",
    "\n",
    "print( 'True label: ' + label_true )\n",
    "print( 'Pred. label: ' + label_pred )\n",
    "# print( pred.tolist() )\n",
    "\n",
    "pred_latex = Latex(f'${label_pred}$')\n",
    "display(pred_latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "model.eval()\n",
    "valid_cer = 0.0\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(tqdm(eval_dataloader)):\n",
    "        # run batch generation\n",
    "        outputs = model.generate(batch[\"pixel_values\"].to(device))\n",
    "        # compute metrics\n",
    "        cer = compute_cer(pred_ids=outputs, label_ids=batch[\"labels\"])\n",
    "        \n",
    "        valid_cer += cer\n",
    "\n",
    "print(\"Validation CER:\", valid_cer / len(eval_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_and_label_str(pred, label):\n",
    "    pred_str = tokenizer.decode_batch(pred.tolist(), skip_special_tokens=True)\n",
    "    label[label == -100] = tokenizer.token_to_id(\"[PAD]\")\n",
    "    label_str = tokenizer.decode_batch(label.tolist(), skip_special_tokens=True)\n",
    "    return (pred_str, label_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "candidate_corpus = []\n",
    "references_corpus = []\n",
    "valid_bleu = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(tqdm(eval_dataloader)):\n",
    "        # run batch generation\n",
    "        outputs = model.generate(batch[\"pixel_values\"].to(device))\n",
    "        # compute metrics\n",
    "        pred, label = get_pred_and_label_str(outputs, batch[\"labels\"])\n",
    "        \n",
    "        for s in pred: s = s.split(\" \")\n",
    "        for s in label: s = s.split(\" \")\n",
    "        candidate_corpus.extend(pred)\n",
    "        references_corpus.extend(label)\n",
    "    \n",
    "valid_bleu =  nltk.translate.bleu_score.corpus_bleu(\n",
    "        references_corpus, candidate_corpus,\n",
    "        weights=(0.25, 0.25, 0.25, 0.25)\n",
    ")\n",
    "valid_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!v=$version; cp tokenizer-wordlevel.json version_$$v/final\n",
    "!v=$version; tar zcvf version_$$v.tar.gz --directory=version_$$v/final "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "imlatex",
   "language": "python",
   "name": "imlatex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
